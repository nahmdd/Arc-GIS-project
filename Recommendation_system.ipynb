{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuiYadSOj0OZtjqF5b8lhG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nahmdd/Arc-GIS-project/blob/main/Recommendation_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wVckOVEpNnVC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "DATA_FILE = 'customer_support_issues.csv'\n",
        "OUTPUT_DIR = './'"
      ],
      "metadata": {
        "id": "crAsIGU3OnWw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 1: DATA LOADING & EXPLORATION\n",
        "# ============================================================================\n",
        "\n",
        "def load_data(filepath):\n",
        "    \"\"\"Load and prepare data\"\"\"\n",
        "    df = pd.read_csv(filepath)\n",
        "    df['date_reported'] = pd.to_datetime(df['date_reported'])\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "jGwy37IoOr9E"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 2: COMPREHENSIVE ISSUE ANALYSIS\n",
        "# ============================================================================\n",
        "\n",
        "def analyze_issues(df):\n",
        "    \"\"\"Perform detailed issue analysis\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"CUSTOMER SUPPORT ISSUE ANALYSIS & INSIGHTS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # 1. Issue frequency\n",
        "    print(\"\\n1. ISSUE FREQUENCY DISTRIBUTION:\")\n",
        "    print(\"-\" * 50)\n",
        "    issue_counts = df['issue_type'].value_counts()\n",
        "    issue_percentage = (issue_counts / len(df) * 100).round(2)\n",
        "    for issue, count in issue_counts.items():\n",
        "        pct = issue_percentage[issue]\n",
        "        print(f\"   {issue:.<40} {count:>3} ({pct:>5}%)\")\n",
        "\n",
        "    # 2. Severity analysis\n",
        "    print(\"\\n2. SEVERITY ANALYSIS BY ISSUE TYPE:\")\n",
        "    print(\"-\" * 50)\n",
        "    severity_by_issue = df.groupby('issue_type')['severity'].agg(['mean', 'max', 'min'])\n",
        "    severity_by_issue = severity_by_issue.sort_values('mean', ascending=False)\n",
        "    for issue, row in severity_by_issue.iterrows():\n",
        "        print(f\"   {issue:.<35} Avg: {row['mean']:.2f} | Max: {int(row['max'])} | Min: {int(row['min'])}\")\n",
        "\n",
        "    # 3. Resolution metrics\n",
        "    print(\"\\n3. RESOLUTION SUCCESS METRICS:\")\n",
        "    print(\"-\" * 50)\n",
        "    total = len(df)\n",
        "    resolved = df['resolved'].sum()\n",
        "    resolution_rate = (resolved / total * 100)\n",
        "    print(f\"   Total Tickets: {total}\")\n",
        "    print(f\"   Resolved: {resolved} ({resolution_rate:.1f}%)\")\n",
        "    print(f\"   Unresolved: {total - resolved} ({100-resolution_rate:.1f}%)\")\n",
        "\n",
        "    # 4. Resolution time\n",
        "    print(\"\\n4. RESOLUTION TIME METRICS (Hours):\")\n",
        "    print(\"-\" * 50)\n",
        "    resolved_df = df[df['resolved'] == True]\n",
        "    print(f\"   Average: {resolved_df['resolution_time_hours'].mean():.1f}h\")\n",
        "    print(f\"   Median: {resolved_df['resolution_time_hours'].median():.0f}h\")\n",
        "    print(f\"   Max: {resolved_df['resolution_time_hours'].max()}h\")\n",
        "    print(f\"   Min: {resolved_df['resolution_time_hours'].min()}h\")\n",
        "\n",
        "    # 5. Most affected products\n",
        "    print(\"\\n5. MOST AFFECTED PRODUCTS:\")\n",
        "    print(\"-\" * 50)\n",
        "    product_counts = df['product'].value_counts()\n",
        "    for product, count in product_counts.items():\n",
        "        pct = (count / len(df) * 100)\n",
        "        print(f\"   {product:.<40} {count:>3} ({pct:>5.1f}%)\")\n",
        "\n",
        "    # 6. High severity issues\n",
        "    print(\"\\n6. HIGH SEVERITY ISSUES (Severity >= 4):\")\n",
        "    print(\"-\" * 50)\n",
        "    high_severity = df[df['severity'] >= 4]\n",
        "    high_sev_issues = high_severity['issue_type'].value_counts()\n",
        "    for issue, count in high_sev_issues.items():\n",
        "        pct = (count / len(high_severity) * 100)\n",
        "        print(f\"   {issue:.<40} {count:>3} ({pct:>5.1f}%)\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "    return {\n",
        "        'issue_counts': issue_counts,\n",
        "        'severity_analysis': severity_by_issue,\n",
        "        'resolution_rate': resolution_rate,\n",
        "        'product_counts': product_counts\n",
        "    }"
      ],
      "metadata": {
        "id": "rVhRALm7Oww4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 3: BUILD RECOMMENDATION ENGINE\n",
        "# ============================================================================\n",
        "\n",
        "def build_recommendation_engine(df):\n",
        "    \"\"\"Build intelligent recommendation system\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"BUILDING RECOMMENDATION ENGINE\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Encode categorical features\n",
        "    le_issue = LabelEncoder()\n",
        "    le_product = LabelEncoder()\n",
        "    le_solution = LabelEncoder()\n",
        "\n",
        "    df['issue_encoded'] = le_issue.fit_transform(df['issue_type'])\n",
        "    df['product_encoded'] = le_product.fit_transform(df['product'])\n",
        "    df['solution_encoded'] = le_solution.fit_transform(df['recommended_solution'])\n",
        "\n",
        "    # Build feature matrix\n",
        "    feature_matrix = np.column_stack([\n",
        "        df['issue_encoded'],\n",
        "        df['product_encoded'],\n",
        "        df['severity'],\n",
        "        df['resolved'].astype(int),\n",
        "        df['resolution_time_hours'] / 100\n",
        "    ])\n",
        "\n",
        "    # Calculate solution effectiveness\n",
        "    solution_effectiveness = df.groupby('recommended_solution').agg({\n",
        "        'resolved': 'mean',\n",
        "        'resolution_time_hours': 'mean',\n",
        "        'severity': 'mean'\n",
        "    }).reset_index()\n",
        "\n",
        "    solution_effectiveness['effectiveness_score'] = (\n",
        "        (solution_effectiveness['resolved'] * 100) -\n",
        "        (solution_effectiveness['resolution_time_hours'] / 72 * 20)\n",
        "    )\n",
        "\n",
        "    solution_scores = dict(zip(\n",
        "        solution_effectiveness['recommended_solution'],\n",
        "        solution_effectiveness['effectiveness_score']\n",
        "    ))\n",
        "\n",
        "    print(\"\\nSOLUTION EFFECTIVENESS SCORES:\")\n",
        "    print(\"-\" * 50)\n",
        "    for solution, score in sorted(solution_scores.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "        print(f\"   {solution:.<40} Score: {score:>6.2f}\")\n",
        "\n",
        "    return {\n",
        "        'feature_matrix': feature_matrix,\n",
        "        'encoders': {\n",
        "            'issue': le_issue,\n",
        "            'product': le_product,\n",
        "            'solution': le_solution\n",
        "        },\n",
        "        'solution_scores': solution_scores,\n",
        "        'df': df\n",
        "    }"
      ],
      "metadata": {
        "id": "FVMbOZPbO9Gl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 4: RECOMMENDATION FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "def recommend_products(engine, issue_type, product, severity, top_n=5):\n",
        "    \"\"\"\n",
        "    Generate product recommendations based on issue characteristics\n",
        "\n",
        "    Args:\n",
        "        engine: Recommendation engine object\n",
        "        issue_type: Type of issue reported\n",
        "        product: Affected product\n",
        "        severity: Issue severity (1-5)\n",
        "        top_n: Number of recommendations\n",
        "\n",
        "    Returns:\n",
        "        List of recommended solutions with scores\n",
        "    \"\"\"\n",
        "\n",
        "    le_issue = engine['encoders']['issue']\n",
        "    le_product = engine['encoders']['product']\n",
        "    feature_matrix = engine['feature_matrix']\n",
        "    solution_scores = engine['solution_scores']\n",
        "    df = engine['df']\n",
        "\n",
        "    # Create query vector\n",
        "    issue_idx = le_issue.transform([issue_type])[0]\n",
        "    product_idx = le_product.transform([product])[0]\n",
        "\n",
        "    query_vector = np.array([\n",
        "        issue_idx,\n",
        "        product_idx,\n",
        "        severity,\n",
        "        1,\n",
        "        50 / 100\n",
        "    ]).reshape(1, -1)\n",
        "\n",
        "    # Calculate similarity\n",
        "    similarities = cosine_similarity(query_vector, feature_matrix)[0]\n",
        "    top_indices = np.argsort(similarities)[::-1][:top_n * 3]\n",
        "\n",
        "    # Extract and rank recommendations\n",
        "    recommended_solutions = df.iloc[top_indices]['recommended_solution'].values\n",
        "    recommendations = []\n",
        "\n",
        "    for solution in recommended_solutions:\n",
        "        if solution not in [r['product'] for r in recommendations]:\n",
        "            recommendations.append({\n",
        "                'product': solution,\n",
        "                'effectiveness_score': solution_scores.get(solution, 0),\n",
        "                'frequency': len(df[df['recommended_solution'] == solution])\n",
        "            })\n",
        "\n",
        "    return sorted(recommendations, key=lambda x: x['effectiveness_score'], reverse=True)[:top_n]\n"
      ],
      "metadata": {
        "id": "GG4XaFkTPCEA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 5: VISUALIZATION FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def create_analysis_dashboard(df):\n",
        "    \"\"\"Create comprehensive analysis dashboard\"\"\"\n",
        "\n",
        "    print(\"\\nGenerating visualizations...\")\n",
        "\n",
        "    fig = plt.figure(figsize=(18, 14))\n",
        "\n",
        "    # 1. Issue distribution\n",
        "    ax1 = plt.subplot(3, 3, 1)\n",
        "    issue_counts = df['issue_type'].value_counts()\n",
        "    colors = sns.color_palette(\"husl\", len(issue_counts))\n",
        "    ax1.pie(issue_counts.values, labels=issue_counts.index, autopct='%1.1f%%', colors=colors)\n",
        "    ax1.set_title('Issue Type Distribution', fontweight='bold')\n",
        "\n",
        "    # 2. Issue frequency\n",
        "    ax2 = plt.subplot(3, 3, 2)\n",
        "    issue_counts.plot(kind='barh', ax=ax2, color=colors)\n",
        "    ax2.set_xlabel('Count')\n",
        "    ax2.set_title('Issue Frequency', fontweight='bold')\n",
        "    ax2.invert_yaxis()\n",
        "\n",
        "    # 3. Severity distribution\n",
        "    ax3 = plt.subplot(3, 3, 3)\n",
        "    severity_dist = df['severity'].value_counts().sort_index()\n",
        "    ax3.bar(severity_dist.index, severity_dist.values,\n",
        "            color=['#2ecc71', '#f39c12', '#e74c3c', '#c0392b', '#8b0000'][:len(severity_dist)])\n",
        "    ax3.set_xlabel('Severity Level')\n",
        "    ax3.set_ylabel('Count')\n",
        "    ax3.set_title('Severity Distribution', fontweight='bold')\n",
        "\n",
        "    # 4. Resolution rate\n",
        "    ax4 = plt.subplot(3, 3, 4)\n",
        "    resolution_rate = (df['resolved'].sum() / len(df) * 100)\n",
        "    ax4.pie([resolution_rate, 100-resolution_rate], labels=['Resolved', 'Unresolved'],\n",
        "            autopct='%1.1f%%', colors=['#2ecc71', '#e74c3c'])\n",
        "    ax4.set_title('Resolution Success Rate', fontweight='bold')\n",
        "\n",
        "    # 5. Resolution time by issue\n",
        "    ax5 = plt.subplot(3, 3, 5)\n",
        "    avg_time = df.groupby('issue_type')['resolution_time_hours'].mean().sort_values(ascending=False)\n",
        "    ax5.barh(range(len(avg_time)), avg_time.values, color=sns.color_palette(\"RdYlGn_r\", len(avg_time)))\n",
        "    ax5.set_yticks(range(len(avg_time)))\n",
        "    ax5.set_yticklabels(avg_time.index)\n",
        "    ax5.set_xlabel('Avg Time (Hours)')\n",
        "    ax5.set_title('Resolution Time by Issue', fontweight='bold')\n",
        "\n",
        "    # 6. Products affected\n",
        "    ax6 = plt.subplot(3, 3, 6)\n",
        "    product_counts = df['product'].value_counts()\n",
        "    ax6.bar(range(len(product_counts)), product_counts.values,\n",
        "            color=sns.color_palette(\"coolwarm\", len(product_counts)))\n",
        "    ax6.set_xticks(range(len(product_counts)))\n",
        "    ax6.set_xticklabels(product_counts.index, rotation=45, ha='right')\n",
        "    ax6.set_ylabel('Issues')\n",
        "    ax6.set_title('Issues by Product', fontweight='bold')\n",
        "\n",
        "    # 7. Heatmap\n",
        "    ax7 = plt.subplot(3, 3, 7)\n",
        "    pivot_data = pd.crosstab(df['issue_type'], df['severity'])\n",
        "    sns.heatmap(pivot_data, annot=True, fmt='d', cmap='YlOrRd', ax=ax7)\n",
        "    ax7.set_title('Issue Type vs Severity', fontweight='bold')\n",
        "\n",
        "    # 8. Resolution by issue\n",
        "    ax8 = plt.subplot(3, 3, 8)\n",
        "    res_by_issue = df.groupby('issue_type')['resolved'].apply(lambda x: x.sum()/len(x)*100).sort_values(ascending=False)\n",
        "    ax8.barh(range(len(res_by_issue)), res_by_issue.values, color=sns.color_palette(\"Greens_d\", len(res_by_issue)))\n",
        "    ax8.set_yticks(range(len(res_by_issue)))\n",
        "    ax8.set_yticklabels(res_by_issue.index)\n",
        "    ax8.set_xlabel('Resolution Rate (%)')\n",
        "    ax8.set_title('Success Rate by Issue', fontweight='bold')\n",
        "\n",
        "    # 9. Temporal trend\n",
        "    ax9 = plt.subplot(3, 3, 9)\n",
        "    issues_monthly = df.set_index('date_reported').resample('M').size()\n",
        "    ax9.plot(issues_monthly.index, issues_monthly.values, marker='o', linewidth=2, markersize=8, color='#3498db')\n",
        "    ax9.fill_between(issues_monthly.index, issues_monthly.values, alpha=0.3, color='#3498db')\n",
        "    ax9.set_xlabel('Month')\n",
        "    ax9.set_ylabel('Issues')\n",
        "    ax9.set_title('Ticket Volume Over Time', fontweight='bold')\n",
        "    ax9.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{OUTPUT_DIR}analysis_dashboard.png', dpi=300, bbox_inches='tight')\n",
        "    print(\"✓ Dashboard saved: analysis_dashboard.png\")\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "lNpi748lPGtc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 6: EXPORT RESULTS\n",
        "# ============================================================================\n",
        "\n",
        "def export_recommendations_report(engine):\n",
        "    \"\"\"Generate and export detailed recommendations report\"\"\"\n",
        "\n",
        "    df = engine['df']\n",
        "\n",
        "    # Test cases\n",
        "    test_cases = [\n",
        "        ('Software Bug', 'Cloud Analytics', 5),\n",
        "        ('Performance Issues', 'API Gateway', 4),\n",
        "        ('Data Sync Problem', 'Mobile App', 5),\n",
        "        ('Connectivity Issues', 'API Gateway', 3),\n",
        "        ('Authentication Error', 'Software Suite Pro', 4),\n",
        "    ]\n",
        "\n",
        "    report = \"PRODUCT RECOMMENDATION SYSTEM - RECOMMENDATIONS REPORT\\n\"\n",
        "    report += \"=\"*70 + \"\\n\\n\"\n",
        "\n",
        "    for i, (issue, product, severity) in enumerate(test_cases, 1):\n",
        "        recommendations = recommend_products(engine, issue, product, severity)\n",
        "\n",
        "        report += f\"CASE {i}: {issue}\\n\"\n",
        "        report += f\"Product: {product} | Severity: {severity}/5\\n\"\n",
        "        report += \"-\"*70 + \"\\n\"\n",
        "        report += f\"{'#':<3} {'Recommended Solution':<40} {'Score':<10} {'Freq':<6}\\n\"\n",
        "        report += \"-\"*70 + \"\\n\"\n",
        "\n",
        "        for j, rec in enumerate(recommendations, 1):\n",
        "            report += f\"{j:<3} {rec['product']:<40} {rec['effectiveness_score']:>6.2f}   {rec['frequency']:>4}\\n\"\n",
        "\n",
        "        report += \"\\n\"\n",
        "\n",
        "    with open(f'{OUTPUT_DIR}recommendations_report.txt', 'w') as f:\n",
        "        f.write(report)\n",
        "\n",
        "    print(\"✓ Recommendations report saved: recommendations_report.txt\")\n",
        "\n",
        "def export_analysis_summary(analysis_results):\n",
        "    \"\"\"Export analysis summary\"\"\"\n",
        "\n",
        "    summary = \"DATA ANALYSIS SUMMARY\\n\"\n",
        "    summary += \"=\"*70 + \"\\n\\n\"\n",
        "\n",
        "    summary += \"ISSUE FREQUENCY:\\n\"\n",
        "    for issue, count in analysis_results['issue_counts'].items():\n",
        "        summary += f\"  {issue}: {count}\\n\"\n",
        "\n",
        "    summary += \"\\nSEVERITY ANALYSIS:\\n\"\n",
        "    for issue, row in analysis_results['severity_analysis'].iterrows():\n",
        "        summary += f\"  {issue}: Avg={row['mean']:.2f}, Max={int(row['max'])}, Min={int(row['min'])}\\n\"\n",
        "\n",
        "    summary += f\"\\nRESOLUTION RATE: {analysis_results['resolution_rate']:.1f}%\\n\"\n",
        "\n",
        "    with open(f'{OUTPUT_DIR}analysis_summary.txt', 'w') as f:\n",
        "        f.write(summary)\n",
        "\n",
        "    print(\"✓ Analysis summary saved: analysis_summary.txt\")\n"
      ],
      "metadata": {
        "id": "1R1XhdcNPLYu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"INTELLIGENT PRODUCT RECOMMENDATION SYSTEM\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Step 1: Load data\n",
        "    print(\"\\n[1] Loading data...\")\n",
        "    df = load_data(DATA_FILE)\n",
        "    print(f\"✓ Loaded {len(df)} records\")\n",
        "\n",
        "    # Step 2: Analyze issues\n",
        "    print(\"\\n[2] Analyzing issues...\")\n",
        "    analysis_results = analyze_issues(df)\n",
        "\n",
        "    # Step 3: Build recommendation engine\n",
        "    print(\"\\n[3] Building recommendation engine...\")\n",
        "    engine = build_recommendation_engine(df)\n",
        "    print(\"✓ Engine built successfully\")\n",
        "\n",
        "    # Step 4: Generate recommendations\n",
        "    print(\"\\n[4] Generating recommendations...\")\n",
        "    test_recommendations = recommend_products(\n",
        "        engine, 'Software Bug', 'Cloud Analytics', 5\n",
        "    )\n",
        "    print(\"\\nSample Recommendations for 'Software Bug' on 'Cloud Analytics' (Severity 5):\")\n",
        "    for i, rec in enumerate(test_recommendations, 1):\n",
        "        print(f\"   {i}. {rec['product']} (Score: {rec['effectiveness_score']:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHCRS0SBPPmP",
        "outputId": "ec780174-7941-4ae5-a0d8-ffa40c34b477"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "INTELLIGENT PRODUCT RECOMMENDATION SYSTEM\n",
            "======================================================================\n",
            "\n",
            "[1] Loading data...\n",
            "✓ Loaded 500 records\n",
            "\n",
            "[2] Analyzing issues...\n",
            "\n",
            "======================================================================\n",
            "CUSTOMER SUPPORT ISSUE ANALYSIS & INSIGHTS\n",
            "======================================================================\n",
            "\n",
            "1. ISSUE FREQUENCY DISTRIBUTION:\n",
            "--------------------------------------------------\n",
            "   Software Bug............................ 133 ( 26.6%)\n",
            "   Performance Issues......................  93 ( 18.6%)\n",
            "   Connectivity Issues.....................  85 ( 17.0%)\n",
            "   Authentication Error....................  69 ( 13.8%)\n",
            "   Data Sync Problem.......................  59 ( 11.8%)\n",
            "   Compatibility Issue.....................  33 (  6.6%)\n",
            "   Installation Error......................  28 (  5.6%)\n",
            "\n",
            "2. SEVERITY ANALYSIS BY ISSUE TYPE:\n",
            "--------------------------------------------------\n",
            "   Software Bug....................... Avg: 3.93 | Max: 5 | Min: 3\n",
            "   Data Sync Problem.................. Avg: 3.93 | Max: 5 | Min: 3\n",
            "   Authentication Error............... Avg: 3.39 | Max: 4 | Min: 3\n",
            "   Connectivity Issues................ Avg: 3.02 | Max: 4 | Min: 2\n",
            "   Compatibility Issue................ Avg: 2.97 | Max: 4 | Min: 2\n",
            "   Performance Issues................. Avg: 2.92 | Max: 4 | Min: 2\n",
            "   Installation Error................. Avg: 2.46 | Max: 3 | Min: 2\n",
            "\n",
            "3. RESOLUTION SUCCESS METRICS:\n",
            "--------------------------------------------------\n",
            "   Total Tickets: 500\n",
            "   Resolved: 421 (84.2%)\n",
            "   Unresolved: 79 (15.8%)\n",
            "\n",
            "4. RESOLUTION TIME METRICS (Hours):\n",
            "--------------------------------------------------\n",
            "   Average: 35.2h\n",
            "   Median: 35h\n",
            "   Max: 71h\n",
            "   Min: 1h\n",
            "\n",
            "5. MOST AFFECTED PRODUCTS:\n",
            "--------------------------------------------------\n",
            "   Cloud Analytics......................... 125 ( 25.0%)\n",
            "   API Gateway............................. 111 ( 22.2%)\n",
            "   Software Suite Pro......................  92 ( 18.4%)\n",
            "   Mobile App..............................  89 ( 17.8%)\n",
            "   Data Manager............................  83 ( 16.6%)\n",
            "\n",
            "6. HIGH SEVERITY ISSUES (Severity >= 4):\n",
            "--------------------------------------------------\n",
            "   Software Bug............................  82 ( 38.0%)\n",
            "   Data Sync Problem.......................  40 ( 18.5%)\n",
            "   Connectivity Issues.....................  29 ( 13.4%)\n",
            "   Performance Issues......................  27 ( 12.5%)\n",
            "   Authentication Error....................  27 ( 12.5%)\n",
            "   Compatibility Issue.....................  11 (  5.1%)\n",
            "\n",
            "======================================================================\n",
            "\n",
            "[3] Building recommendation engine...\n",
            "\n",
            "======================================================================\n",
            "BUILDING RECOMMENDATION ENGINE\n",
            "======================================================================\n",
            "\n",
            "SOLUTION EFFECTIVENESS SCORES:\n",
            "--------------------------------------------------\n",
            "   Legacy Support.......................... Score:  93.89\n",
            "   Compatibility Layer..................... Score:  88.89\n",
            "   Setup Wizard............................ Score:  87.78\n",
            "   Performance Optimizer................... Score:  86.46\n",
            "   Connection Optimizer.................... Score:  84.60\n",
            "   Resource Monitor........................ Score:  83.17\n",
            "   Two-Factor Module....................... Score:  82.74\n",
            "   Backup Manager.......................... Score:  82.56\n",
            "   Identity Manager........................ Score:  81.57\n",
            "   System Checker.......................... Score:  80.25\n",
            "✓ Engine built successfully\n",
            "\n",
            "[4] Generating recommendations...\n",
            "\n",
            "Sample Recommendations for 'Software Bug' on 'Cloud Analytics' (Severity 5):\n",
            "   1. Performance Optimizer (Score: 86.46)\n",
            "   2. Cache Manager (Score: 78.37)\n",
            "   3. Load Balancer Pro (Score: 76.45)\n",
            "   4. Core Engine Update (Score: 75.27)\n",
            "   5. Bug Fix Patch v2.1 (Score: 73.80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Create visualizations\n",
        "print(\"\\n[5] Creating visualizations...\")\n",
        "create_analysis_dashboard(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DdaUprnPS9Y",
        "outputId": "fef1ac87-6ecd-4b9b-c4f6-acc875da4d54"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[5] Creating visualizations...\n",
            "\n",
            "Generating visualizations...\n",
            "✓ Dashboard saved: analysis_dashboard.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Export results\n",
        "print(\"\\n[6] Exporting results...\")\n",
        "export_recommendations_report(engine)\n",
        "export_analysis_summary(analysis_results)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXECUTION COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nGenerated files:\")\n",
        "print(\"  • customer_support_issues.csv - Dataset\")\n",
        "print(\"  • analysis_dashboard.png - Comprehensive visualization\")\n",
        "print(\"  • recommendations_report.txt - Detailed recommendations\")\n",
        "print(\"  • analysis_summary.txt - Analysis summary\")\n",
        "print(\"\\n\" + \"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e43fzDP5Pr0b",
        "outputId": "18a5433c-4d18-4aae-a4cc-8bae6bc830a7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[6] Exporting results...\n",
            "✓ Recommendations report saved: recommendations_report.txt\n",
            "✓ Analysis summary saved: analysis_summary.txt\n",
            "\n",
            "======================================================================\n",
            "EXECUTION COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "Generated files:\n",
            "  • customer_support_issues.csv - Dataset\n",
            "  • analysis_dashboard.png - Comprehensive visualization\n",
            "  • recommendations_report.txt - Detailed recommendations\n",
            "  • analysis_summary.txt - Analysis summary\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}